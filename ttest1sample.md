Youâ€™ll see exactly *what problem a t-test solves*.

---

# ğŸ¯ The Story: Are my dice rolls fair?

But instead of heads/tails, weâ€™ll measure **waiting time**.

## Step 1 â€” The setup

Suppose a game designer claims:

> â€œOn average, players finish level 1 in **10 seconds**.â€

You test 8 players and record their times:

```
[12, 9, 11, 13, 8, 10, 12, 14]
```

Question:

> Is the true average really 10 seconds?
> Or is the claim wrong?

This is **exactly** the same logic as the fair-coin question, but now data are real numbers instead of counts.

---

# Step 2 â€” Define hypotheses

Null hypothesis (boring world):

> **Hâ‚€: average time = 10 seconds**

Alternative:

> **Hâ‚: average time â‰  10 seconds**

---

# Step 3 â€” Look at the data

Compute sample mean:

[
\bar x = 11.125
]

So players seem slower than claimed.
But: maybe this happened by chance. Small samples fluctuate.

---

# Step 4 â€” Measure â€œsurpriseâ€

If Hâ‚€ were true (mean = 10), how surprising is seeing a sample mean of 11.125?

But we must scale by variability â€” some players differ more than others.

Compute sample standard deviation:

[
s \approx 2.03
]

Standard error of mean:

[
SE = s / \sqrt{8} \approx 0.718
]

Now form the **t-statistic**:

[
t = \frac{11.125 - 10}{0.718} \approx 1.57
]

This says:

> â€œThe observed mean is 1.57 standard-errors away from the null claim.â€

---

# Step 5 â€” Convert t â†’ p-value

For 7 degrees of freedom:

[
p \approx 0.16
]

---

# Step 6 â€” Make decision

Choose Î± = 0.05.

Since:

[
p = 0.16 > 0.05
]

ğŸ‘‰ **Fail to reject Hâ‚€**

---

# Step 7 â€” Plain English conclusion

> â€œWith only 8 players, the observed average of 11.1 seconds is not unusual enough to contradict the claim of 10 seconds.â€

We do **not** say:

* â€œThe claim is trueâ€
* or â€œPlayers are slowerâ€

We only say:

* **Not enough evidence**

---

# Step 8 â€” Python reproduction

```python
import numpy as np
from scipy.stats import ttest_1samp

times = np.array([12,9,11,13,8,10,12,14])
t_stat, p = ttest_1samp(times, 10)

t_stat, p
```

---

# Step 9 â€” Connect back to coin

| Coin problem       | Time problem      |
| ------------------ | ----------------- |
| Heads count        | Sample mean       |
| Binomial noise     | Measurement noise |
| Binomial test      | t-test            |
| p-value = surprise | same              |

**Same logic. Different data type.**

---

# Step 10 â€” Key memory hook

> **t-test = â€œIs my sample average unusually far from the claimed average, relative to natural variability?â€**


